---
toc: true
hide: true
layout: post
description: applying bert for text classification tasks
categories: [nlp]
image: images/bert/nlp_title.png
title: Transfer Learning with BERT

---

There has been paradigm shift in the field of Natural Langauge Processing (NLP). Various Pre-trained language models like BERT are achieving state of the art results for NLP tasks like  text classifcation, Name entity recognition and Question Answering.

In this blog, you  will learn how to apply transfer learning based approach BERT for text classification tasks.

## Overview of BERT


include imge 

- tokenization
- Generating vocabulary of unique tokens and converting words to indices (Numericalization)
- Loading pretrained vectors e.g. Glove, Word2vec, Fasttext
- Padding text with zeros in case of variable lengths
- Dataloading and batching
- Model creation and training
- Prediction using trained Model





